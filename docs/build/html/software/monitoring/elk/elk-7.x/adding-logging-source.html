

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Adding a new Logging Source &mdash; apolo-docs 0.1 documentation</title>
      <link rel="stylesheet" href="../../../../_static/css/theme_overrides.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/sidebar.css" type="text/css" />

  
      <script src="../../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../../_static/documentation_options.js?v=2709fde1"></script>
      <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <link rel="next" title="Grafana" href="../../grafana/index.html" />
    <link rel="prev" title="Testing" href="testing.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

  
    <a href="../../../../index.html" class="icon icon-home"> apolo-docs
  

  
    </a>

    

    
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../../gettingstarted/index.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../supercomputers/index.html">Supercomputers</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../index.html">Software</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../virtualization/index.html">Virtualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../programminglanguages/index.html">Programming Languages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../applications/index.html">Scientific Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../managementsoftware/index.html">Management Software</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../provisioning/index.html">Provisioning</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../index.html">Monitoring</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../../architecture/index.html">Monitoring Architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../nagios/index.html">Nagios</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../sensu/index.html">Sensu</a></li>
<li class="toctree-l3 current"><a class="reference internal" href="../index.html">ELK</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../elk-6.x/index.html">ELK Stack 6.x Installation and Configuration</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="index.html">ELK Stack 7.x</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../grafana/index.html">Grafana</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../apolomonitoring/index.html">Apolo Monitoring</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../sensu_go/index.html">Sensu Go</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../operatingsystems/index.html">Operating Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_libraries/index.html">Scientific Libraries</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../accelerators/index.html">Accelerators</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../how-to-acknowledge.html">How to Acknowledge</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../report-a-bug.html">Report a Bug</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">apolo-docs</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Software</a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Monitoring</a></li>
          <li class="breadcrumb-item"><a href="../index.html">ELK</a></li>
          <li class="breadcrumb-item"><a href="index.html">ELK Stack 7.x</a></li>
      <li class="breadcrumb-item active">Adding a new Logging Source</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../../_sources/software/monitoring/elk/elk-7.x/adding-logging-source.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="adding-a-new-logging-source">
<span id="new-source-7-x"></span><span id="adding-logging-source-index"></span><h1><a class="toc-backref" href="#id1" role="doc-backlink">Adding a new Logging Source</a><a class="headerlink" href="#adding-a-new-logging-source" title="Link to this heading"></a></h1>
<p>Adding a new logging source is simple if the ELK stack is alreary installed. Follow the following steps:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Even though this guide uses Filebeat as log collector, the principles should be the same for others as well.</p>
</div>
<nav class="contents" id="contents">
<p class="topic-title">Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#adding-a-new-logging-source" id="id1">Adding a new Logging Source</a></p>
<ul>
<li><p><a class="reference internal" href="#logging-source" id="id2">1. Logging Source</a></p></li>
<li><p><a class="reference internal" href="#filtering" id="id3">2. Filtering</a></p></li>
<li><p><a class="reference internal" href="#creating-indexes-and-mappings" id="id4">3. Creating Indexes and Mappings</a></p></li>
<li><p><a class="reference internal" href="#adding-the-log-path-to-filebeat" id="id5">4. Adding the log path to Filebeat</a></p></li>
<li><p><a class="reference internal" href="#create-index-patterns" id="id6">5. Create Index Patterns</a></p></li>
<li><p><a class="reference internal" href="#plot-the-data" id="id7">6 . Plot the data</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="logging-source">
<h2><a class="toc-backref" href="#id2" role="doc-backlink">1. Logging Source</a><a class="headerlink" href="#logging-source" title="Link to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Identify the logging source. For example, it required to track the users that log in to an SSH server. Identify where the service writes its logs. In this case <code class="code highlight bash docutils literal highlight-bash">/var/log/secure</code>.</p></li>
<li><p>Knowing where to take the logs from, identify the messages that are useful. For example:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span>Jun<span class="w"> </span><span class="m">25</span><span class="w"> </span><span class="m">15</span>:30:02<span class="w"> </span>elk<span class="w"> </span>sshd<span class="o">[</span><span class="m">5086</span><span class="o">]</span>:<span class="w"> </span>pam_unix<span class="o">(</span>sshd:session<span class="o">)</span>:<span class="w"> </span>session<span class="w"> </span>closed<span class="w"> </span><span class="k">for</span><span class="w"> </span>user<span class="w"> </span>vagrant
<span class="linenos">2</span>Jun<span class="w"> </span><span class="m">25</span><span class="w"> </span><span class="m">17</span>:08:11<span class="w"> </span>elk<span class="w"> </span>sshd<span class="o">[</span><span class="m">5185</span><span class="o">]</span>:<span class="w"> </span>Accepted<span class="w"> </span>publickey<span class="w"> </span><span class="k">for</span><span class="w"> </span>vagrant<span class="w"> </span>from<span class="w"> </span><span class="m">10</span>.0.2.2<span class="w"> </span>port<span class="w"> </span><span class="m">54128</span><span class="w"> </span>ssh2:<span class="w"> </span>RSA<span class="w"> </span>SHA256:64u6q4IdjxSFhVGdqwJa60y/nMx7oZWb0dAsNqMIMvE
<span class="linenos">3</span>Jun<span class="w"> </span><span class="m">25</span><span class="w"> </span><span class="m">17</span>:08:11<span class="w"> </span>elk<span class="w"> </span>sshd<span class="o">[</span><span class="m">5185</span><span class="o">]</span>:<span class="w"> </span>pam_unix<span class="o">(</span>sshd:session<span class="o">)</span>:<span class="w"> </span>session<span class="w"> </span>opened<span class="w"> </span><span class="k">for</span><span class="w"> </span>user<span class="w"> </span>vagrant<span class="w"> </span>by<span class="w"> </span><span class="o">(</span><span class="nv">uid</span><span class="o">=</span><span class="m">0</span><span class="o">)</span>
</pre></div>
</div>
<p>The first and third logs might not be useful in this case, but the second log is the one that helps.</p>
</section>
<section id="filtering">
<span id="how-to-filter-7-x"></span><h2><a class="toc-backref" href="#id3" role="doc-backlink">2. Filtering</a><a class="headerlink" href="#filtering" title="Link to this heading"></a></h2>
<p>Now it’s time to parse and filter the important information. It can be accomplished using Logstash and the Kibana’s Grok debugging tool.
Grok is a Logstash filtering plugin used to match patterns and extract useful information from the logs. For more information about Grok read <a class="reference external" href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html">the documentation</a>.
Follow these steps:</p>
<ol class="arabic simple">
<li><p>Open Kibana. Go to <strong>Dev Tools</strong> -&gt; <strong>Grok Debugger</strong>. Here can be found three main text boxes:</p></li>
</ol>
<blockquote>
<div><ul class="simple">
<li><p>The first one is where to put the log that will be filtered.</p></li>
<li><p>The second one is where a regular expression is written. This regular expression tells Grok how to filter the log.</p></li>
<li><p>The third one is where Grok shows its results in JSON format, which is the format used by Elasticsearch to inxed everything.</p></li>
</ul>
</div></blockquote>
<p>2. But, how to filter an arbitrary log?. Grok uses a regular expression library called <a class="reference external" href="https://github.com/kkos/oniguruma/blob/master/doc/RE">Oniguruma</a>.
This library has a way match patterns in the log. These patterns can be tagged with a name. That name is important because that is how the information will be found in Elasticsearch.
Here is the regular expression that matches the <code class="code highlight bash docutils literal highlight-bash">timestamp</code>, the <code class="code highlight bash docutils literal highlight-bash">event</code> state (if the user could or couldn’t log in), the <code class="code highlight bash docutils literal highlight-bash">user</code> that tried to log in,
the <code class="code highlight bash docutils literal highlight-bash">ip<span class="w"> </span>address</code> that is trying to log in, the <code class="code highlight bash docutils literal highlight-bash">port</code> number and the user <code class="code highlight bash docutils literal highlight-bash">signature</code>.
Check out the following regular expression:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%<span class="o">{</span>SYSLOGTIMESTAMP:log_timestamp<span class="o">}</span><span class="w"> </span>%<span class="o">{</span>SYSLOGHOST:system_hostname<span class="o">}</span><span class="w"> </span>sshd<span class="o">(</span>.*<span class="o">)</span>?:<span class="w"> </span><span class="o">(</span>?&lt;sshd_event&gt;<span class="o">[</span>a-zA-Z<span class="o">]</span>+<span class="o">)</span><span class="w"> </span>%<span class="o">{</span>DATA:sshd_method<span class="o">}</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="o">(</span>invalid<span class="w"> </span>user<span class="w"> </span><span class="o">)</span>?%<span class="o">{</span>DATA:sshd_user<span class="o">}</span><span class="w"> </span>from<span class="w"> </span>%<span class="o">{</span>IPORHOST:sshd_guest_ip<span class="o">}</span><span class="w"> </span>port<span class="w"> </span>%<span class="o">{</span>NUMBER:sshd_guest_port<span class="o">}</span><span class="w"> </span>ssh2<span class="o">(</span>:<span class="w"> </span>%<span class="o">{</span>GREEDYDATA:sshd_guest_signature<span class="o">})</span>?
</pre></div>
</div>
<p>With the log in the first text box and the regular expression in the second text box, press <strong>Simulate</strong>. Up to this point the Kibana’s Grok debugger should look like this:</p>
<img alt="../../../../_images/grok.png" src="../../../../_images/grok.png" />
</div></blockquote>
<ol class="arabic simple" start="3">
<li><p>Let’s break down the regular expression into chunks:</p>
<ul class="simple">
<li><p><strong>%{SYSLOGTIMESTAMP:log_timestamp}</strong>: <em>SYSLOGTIMESTAMP</em> is a Grok built-in regular expression. These and many more built-in regular expressions can be found in this <a class="reference external" href="https://github.com/logstash-plugins/logstash-patterns-core/blob/master/patterns/grok-patterns">repository</a>. <strong>log_timestamp</strong> is how was decided to <em>tag</em> the matched string. Therefore, this expression will match from <strong>Jun …</strong> to <strong>… 17:08:11</strong>.</p></li>
<li><p><strong>%{SYSLOGHOST:system_hostname}</strong>: <em>SYSLOGHOST</em> matches the log hostname and identifies it as <strong>system_hostname</strong>. Note that this is the sshd server’s hostname, not the user’s hostname.</p></li>
<li><p><strong>sshd(.*)?</strong>: This expression matches the literal string ‘sshd’, followed by anything except new lines (the dot) ‘.’. The parentheses are grouping operators, therefore, they group the expression ‘.*’, and this whole expression is optional, ‘?’, which means it might or might not appear in the log. In other words, there might not be something after the word ‘sshd’, if so, then it won’t match anything. Note that this expression doesn’t have any identifier, that’s because what’s matched here is not important.</p></li>
<li><p><strong>(?&lt;sshd_event&gt;[a-zA-Z]+)</strong>: This is an important expression. The expression ‘(?&lt;xxx&gt;…)’ can be used when there isn’t a default Grok pattern for what is needed. Instead of ‘xxx’, type the name/tag that will be given to the matched string. Instead of ‘…’ put the regular expression that matches the needed string. In this case, the <strong>event</strong> is composed only by letters, so ‘[a-zA-Z]’ means any lowercase or uppercase letter, the ‘+’ means one or more times. This expression can be replaced by the Grok default pattern <strong>%{DATA:sshd_event}</strong>, but for the purpose of this guide, ‘(?&lt;xxx&gt;…)’ was used so that it can be used whenever needed.</p></li>
<li><p><strong>%{DATA:sshd_method}</strong>: <em>DATA</em> matches anything (but new lines). The key is that this <em>anything</em> may or may not appear, in other words, it’s optional. But <strong>sshd_method</strong> is always needed, why to let it as optional?. Well, it’s just for simplicity, instead of creating a new regular expression it’s simpler to just use the built-in <strong>%{DATA:…}</strong>.</p></li>
<li><p><strong>(invalid user )?</strong>: If the event is ‘Invalid’ instead of ‘Accepted’ or ‘Failed’ this string appears, so that’s why it is optional.</p></li>
<li><p><strong>%{DATA:sshd_user}</strong>: <em>DATA</em> matches anything (but new lines), but that anything may or may not appear.</p></li>
<li><p><strong>%{IPORHOST:sshd_guest_ip}</strong>: <em>IPORHOST</em> matches IP addresses, including IPv6. That IP address is given the identifier <em>sshd_guest_ip</em>.</p></li>
<li><p><strong>%{NUMBER:sshd_guest_port}</strong>: <em>NUMBER</em> matches numbers, in this case, the client’s port number.</p></li>
<li><p><strong>(: %{GREEDYDATA:sshd_guest_signature})?</strong>: <em>GREEDYDATA</em> matches anything (but new lines). In this case, it matches the guest signature, but sometimes it might not appear, so that’s why it is enclosed in an optional construct ‘(…)?’.</p></li>
<li><p>The other expressions, ‘sshd’, ‘for’, ‘from’, ‘port’, and ‘ssh2’ are literal strings, so Grok has to find them in the string that is being parsed, <strong>otherwise the whole string is rejected</strong>.</p></li>
</ul>
</li>
<li><p>Already having a way to parse the new log, it’s time to change the Logstash pipeline configuration. Before proceeding, it’s recommended to read this short guide about how a <a class="reference external" href="https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html">pipeline configuration file looks</a>. Also, it would be very useful to read about what is the purpose of <a class="reference external" href="https://www.elastic.co/guide/en/logstash/current/index.html">Logstash</a>. Go to the end of the <em>filter</em> section and add the following:</p></li>
</ol>
<blockquote>
<div><div class="highlight-ruby notranslate"><div class="highlight"><pre><span></span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="n">fromsecure</span><span class="o">]</span><span class="w"> </span><span class="p">{</span>

<span class="p">}</span>
</pre></div>
</div>
<p>If this this logging source, <code class="code highlight bash docutils literal highlight-bash">/var/log/secure</code>, was added before, don’t add that <code class="code highlight ruby docutils literal highlight-ruby"><span class="k">if</span></code> sentence, surely it is somewhere else in the <em>filter</em> section. But, why <code class="code highlight ruby docutils literal highlight-ruby"><span class="o">[</span><span class="n">fromsecure</span><span class="o">]</span></code>?, what does that mean?. It checks if the JSON received has a field called <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">fromsecure</span></code>. The existence of that field will be explained later in <a class="reference internal" href="#add-path-filebeat-7-x"><span class="std std-ref">4. Adding the log path to Filebeat</span></a>.</p>
</div></blockquote>
<ol class="arabic simple" start="5">
<li><p>Under the <code class="code highlight ruby docutils literal highlight-ruby"><span class="k">if</span></code> sentence add a <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">grok</span></code> block. This is the way of asking to Logstash to use a <em>filter</em> plugin, in this case <em>Grok</em>. So, add the following:</p></li>
</ol>
<blockquote>
<div><div class="highlight-ruby notranslate"><div class="highlight"><pre><span></span><span class="n">grok</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">match</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;message&quot;</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[]</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">add_field</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">match</span></code> and <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">add_field</span></code> sub-blocks ask Grok to use those options. The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">match</span></code> option is used to parse fields, what was explained two subsections before.
Those fields are passed to the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">filter</span></code> section by the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">input</span></code> section, which in turn receives messages from a <em>Filebeat</em> service, or a <a class="reference external" href="https://www.elastic.co/guide/en/logstash/current/dead-letter-queues.html">Dead letter queue</a>.
The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">add_field</span></code> adds fields to the JSON message in case that the match option successfully matched a string. This is useful in the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">output</span></code> section of the pipeline.
This is useful to send to Elasticsearch only what was successfully parsed, and not everything that arrives at the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">input</span></code> section.</p>
</div></blockquote>
<ol class="arabic simple" start="6">
<li><p>Under the <em>match</em> sub-block and the brackets, and between double quotes, add the regular expression built with the Kibana’s Grok debugger. Under the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">add_field</span></code> sub-block add the following too:</p></li>
</ol>
<blockquote>
<div><div class="highlight-ruby notranslate"><div class="highlight"><pre><span></span><span class="n">grok</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">match</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;message&quot;</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[</span>
<span class="w">      </span><span class="s2">&quot;%{SYSLOGTIMESTAMP:log_timestamp} %{SYSLOGHOST:system_hostname} sshd(.*)?: (?&lt;sshd_event&gt;[a-zA-Z]+) %{DATA:sshd_method} for (invalid user )?%{DATA:sshd_user} from %{IPORHOST:sshd_guest_ip} port %{NUMBER:sshd_guest_port} ssh2(: %{GREEDYDATA:sshd_guest_signature})?&quot;</span>
<span class="w">    </span><span class="o">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">add_field</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="s2">&quot;type&quot;</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;secure_sshd_login_attempt&quot;</span>
<span class="w">    </span><span class="s2">&quot;secure_correctly_filtered&quot;</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;true&quot;</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">type</span></code> field serves to differentiate logs in the same <em>index</em> in Elasticsearch. For example, <code class="code highlight bash docutils literal highlight-bash">/var/log/secure</code> also stores logs about the system security (e.g who executes sudo commands), not only logs about ssh.
The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">secure_correctly_filtered</span></code> is used in the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">output</span></code> section to send only the information that was correctly filtered.</p>
</div></blockquote>
<p>7. The following filter plugin is <strong>extremely important</strong> to correctly visualize the information. Kibana uses a <strong>metafield</strong>, called <code class="code highlight ruby docutils literal highlight-ruby"><span class="vi">@timestamp</span></code>, to organize and show the information based on dates.
Logstash adds that field by default when a log is received in the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">input</span></code> section. The problem is that the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">log_timestamp</span></code> field that we added before has a different date, it has the timestamp that corresponds to the log creation.
The time when the log arrives to Logstash is likely to be very different from the time that the log was generated by the service (in this case sshd). There might be a difference of months, even years, because the log that is being indexed might be from the last month/year.
To solve this problem Logstash has a plugin called <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">date</span></code>. This plugin can be used to replace the information in the metafield <code class="code highlight ruby docutils literal highlight-ruby"><span class="vi">@timestamp</span></code> with any other field that has a timestamp, in this case <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">log_timestamp</span></code>.
It has more <a class="reference external" href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html">options</a> than the two presented here. The basic usage is the following:</p>
<blockquote>
<div><div class="highlight-ruby notranslate"><div class="highlight"><pre><span></span><span class="n">date</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">match</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="s2">&quot;log_timestamp&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;MMM dd yyyy HH:mm:ss&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;MMM d yyyy HH:mm:ss&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;MMM dd HH:mm:ss&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;MMM d HH:mm:ss&quot;</span><span class="w"> </span><span class="o">]</span>
<span class="w">  </span><span class="n">timezone</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;America/Bogota&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">match</span></code> option tells the plugin to parse the field in the first string given in the array, <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">log_timestamp</span></code>.
The following strings are the format in which the field to parse might be built.
For example, “MMM dd yyyy HH:mm:ss”, means that the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">log_timestamp</span></code> field might be in the format:
Three letter month, MMM. A two digit day, dd. A four digit year, yyyy. A two digit hour, HH. A two digit minutes, mm. And a two digit seconds, ss.
The rest of the options tells to the plugin that the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">log_timestamp</span></code> field might have those variants.</p>
<p>The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">timezone</span></code> option tells the plugin to update the timezone in the <code class="code highlight ruby docutils literal highlight-ruby"><span class="vi">@timestamp</span></code> field to the given timezone.
Elasticsearch uses UTC as timezone. It cannot be changed, that is, Elasticsearch uses it to work properly.
Even though we cannot change it, we can update the <code class="code highlight ruby docutils literal highlight-ruby"><span class="vi">@timestamp</span></code> field with our real timezone because Kibana converts it underneath to the browser’s timezone.
Therefore, it is important to have the <strong>same timezone in the browser and in the logs</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This plugin is <strong>used by Grok only</strong> in case of successful parse of the log.</p>
</div>
</div></blockquote>
<ol class="arabic simple" start="8">
<li><p>The following filter plugin is used to remove unnecessary fields from the JSON that will be sent to Elasticsearch. This is how to use it:</p></li>
</ol>
<blockquote>
<div><div class="highlight-ruby notranslate"><div class="highlight"><pre><span></span><span class="n">mutate</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">remove_field</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[</span><span class="s2">&quot;fromsecure&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;log_timestamp&quot;</span><span class="o">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">remove_field</span></code> option is given a list of fields that will be removed.</p>
<ul class="simple">
<li><p>The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">fromsecure</span></code> field is used in the <code class="code highlight ruby docutils literal highlight-ruby"><span class="k">if</span></code> sentence above, so it’s not needed anymore. The procedence of this field is explaned later in <a class="reference internal" href="#add-path-filebeat-7-x"><span class="std std-ref">4. Adding the log path to Filebeat</span></a>.</p></li>
<li><p>The <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">log_timestamp</span></code> is not needed anymore because we already have a field that contains the a timestamp, <code class="code highlight ruby docutils literal highlight-ruby"><span class="vi">@timestamp</span></code>.</p></li>
</ul>
</div></blockquote>
<ol class="arabic simple" start="9">
<li><p>Up to this point there is no need for more Logstash filters. Putting everything together should look like this:</p></li>
</ol>
<blockquote>
<div><div class="highlight-ruby notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1"># /etc/logstash/conf.d/main_pipeline.conf</span>
<span class="linenos"> 2</span>
<span class="linenos"> 3</span><span class="n">input</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 4</span><span class="w">  </span><span class="n">beats</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 5</span><span class="w">    </span><span class="n">port</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;5044&quot;</span>
<span class="linenos"> 6</span><span class="w">  </span><span class="p">}</span>
<span class="linenos"> 7</span>
<span class="linenos"> 8</span><span class="w">  </span><span class="c1"># Events go to the dead_letter_queue when Elasticsearch response has 400/402 code</span>
<span class="linenos"> 9</span><span class="w">  </span><span class="n">dead_letter_queue</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">10</span><span class="w">    </span><span class="n">path</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;/var/log/logstash/dead_letter_queue&quot;</span>
<span class="linenos">11</span><span class="w">    </span><span class="n">tags</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[</span><span class="s2">&quot;recovered_from_dead_letter_queue&quot;</span><span class="o">]</span>
<span class="linenos">12</span><span class="w">  </span><span class="p">}</span>
<span class="linenos">13</span><span class="p">}</span>
<span class="linenos">14</span>
<span class="linenos">15</span><span class="n">filter</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">16</span><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="n">fromsecure</span><span class="o">]</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">17</span>
<span class="linenos">18</span><span class="w">    </span><span class="n">grok</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">19</span><span class="w">      </span><span class="n">match</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">20</span><span class="w">        </span><span class="s2">&quot;message&quot;</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[</span>
<span class="linenos">21</span><span class="w">  	  </span><span class="c1"># Login attemps</span>
<span class="linenos">22</span><span class="w">          </span><span class="s2">&quot;%{SYSLOGTIMESTAMP:log_timestamp} %{SYSLOGHOST:system_hostname} sshd(.*)?: %{DATA:sshd_event} %{DATA:sshd_method} for (invalid user )?%{DATA:sshd_user} from %{IPORHOST:sshd_guest_ip} port %{NUMBER:sshd_guest_port} ssh2(: %{GREEDYDATA:sshd_guest_signature})?&quot;</span>
<span class="linenos">23</span><span class="w">  	</span><span class="o">]</span>
<span class="linenos">24</span><span class="w">      </span><span class="p">}</span>
<span class="linenos">25</span><span class="w">      </span><span class="n">add_field</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;secure_sshd_login_attempt&quot;</span>
<span class="linenos">26</span><span class="w">                     </span><span class="s2">&quot;secure_correctly_filtered&quot;</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;true&quot;</span><span class="w"> </span><span class="p">}</span>
<span class="linenos">27</span><span class="w">    </span><span class="p">}</span>
<span class="linenos">28</span>
<span class="linenos">29</span><span class="w">    </span><span class="c1"># In case of successful parsing, the @timestamp field is updated with the parsed info</span>
<span class="linenos">30</span><span class="w">    </span><span class="n">date</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">31</span><span class="w">      </span><span class="n">match</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[</span><span class="w"> </span><span class="s2">&quot;log_timestamp&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;MMM dd yyyy HH:mm:ss&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;MMM d yyyy HH:mm:ss&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;MMM dd HH:mm:ss&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;MMM d HH:mm:ss&quot;</span><span class="w"> </span><span class="o">]</span>
<span class="linenos">32</span><span class="w">      </span><span class="n">timezone</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;America/Bogota&quot;</span>
<span class="linenos">33</span><span class="w">    </span><span class="p">}</span>
<span class="linenos">34</span>
<span class="linenos">35</span><span class="w">    </span><span class="n">mutate</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">36</span><span class="w">      </span><span class="n">remove_field</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[</span><span class="s2">&quot;fromsecure&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;log_timestamp&quot;</span><span class="o">]</span>
<span class="linenos">37</span><span class="w">    </span><span class="p">}</span>
<span class="linenos">38</span><span class="w">  </span><span class="p">}</span>
<span class="linenos">39</span><span class="p">}</span>
<span class="linenos">40</span>
<span class="linenos">41</span><span class="n">output</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">42</span><span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="o">[</span><span class="n">secure_correctly_filtered</span><span class="o">]</span><span class="w"> </span><span class="p">{</span>
<span class="linenos">43</span><span class="w">    </span><span class="n">elasticsearch</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="c1"># Dead Letter Queue is only supported for elasticsearch output</span>
<span class="linenos">44</span><span class="w">      </span><span class="n">index</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="s2">&quot;secure&quot;</span>
<span class="linenos">45</span><span class="w">      </span><span class="n">hosts</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="o">[</span><span class="s2">&quot;elk:9200&quot;</span><span class="o">]</span>
<span class="linenos">46</span><span class="w">    </span><span class="p">}</span>
<span class="linenos">47</span><span class="w">  </span><span class="p">}</span>
<span class="linenos">48</span><span class="p">}</span>
</pre></div>
</div>
<p>In summary:</p>
<ul class="simple">
<li><p>The first section, <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">input</span></code>, indicates to Logstash where it will receive logs from. In this case Filebeat, on port 5044, and something called the <strong>Dead Letter Queue</strong>. This is where logs that couldn’t be indexed go. For example, Logstash received a log, but Elasticsearch crashed, so the log couldn’t be indexed, then the log is written to the Dead Letter Queue allowing it to be reindexed later.</p></li>
<li><p>The last block, <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">output</span></code>, indicates to Logstash where it will send logs to. In this case Elasticsearch, which is in the host <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">elk</span></code> on port <code class="code highlight ruby docutils literal highlight-ruby"><span class="mi">9200</span></code>, to the <strong>index</strong> <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">secure</span></code>. Elasticsearch indexes will be explained in <a class="reference internal" href="#create-indexes-mappings-7-x"><span class="std std-ref">3. Creating Indexes and Mappings</span></a>, think about them as tables where the logs will be registered.</p></li>
<li><p>Note the <code class="code highlight ruby docutils literal highlight-ruby"><span class="k">if</span></code> sentence in line 42. Recall the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">add_field</span></code> option explained in the Grok filter, well it is used here to send logs to the proper index if and only if, they were correctly filtered by Grok.</p></li>
</ul>
</div></blockquote>
<p>10. Restart the Logstash service and hopefully, everything will work perfectly. Sometimes, the service seems to start correctly but it failed reading the pipeline configuration file (what was just written).
To check that everything is perfect check out the log when Logstash is starting, commonly <code class="code highlight bash docutils literal highlight-bash">/usr/share/logstash/logs/logstash-plain.log</code>. Logs similar to these are a good signal:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[</span><span class="m">2019</span>-07-03T10:04:46,238<span class="o">][</span>INFO<span class="w"> </span><span class="o">][</span>logstash.agent<span class="w">           </span><span class="o">]</span><span class="w"> </span>Pipelines<span class="w"> </span>running<span class="w"> </span><span class="o">{</span>:count<span class="o">=</span>&gt;1,<span class="w"> </span>:running_pipelines<span class="o">=</span>&gt;<span class="o">[</span>:main<span class="o">]</span>,<span class="w"> </span>:non_running_pipelines<span class="o">=</span>&gt;<span class="o">[]}</span>
<span class="o">[</span><span class="m">2019</span>-07-03T10:04:46,705<span class="o">][</span>INFO<span class="w"> </span><span class="o">][</span>org.logstash.beats.Server<span class="o">]</span><span class="w"> </span>Starting<span class="w"> </span>server<span class="w"> </span>on<span class="w"> </span>port:<span class="w"> </span><span class="m">5044</span>
<span class="o">[</span><span class="m">2019</span>-07-03T10:04:50,337<span class="o">][</span>INFO<span class="w"> </span><span class="o">][</span>logstash.agent<span class="w">           </span><span class="o">]</span><span class="w"> </span>Successfully<span class="w"> </span>started<span class="w"> </span>Logstash<span class="w"> </span>API<span class="w"> </span>endpoint<span class="w"> </span><span class="o">{</span>:port<span class="o">=</span>&gt;9600<span class="o">}</span>
</pre></div>
</div>
</div></blockquote>
</section>
<section id="creating-indexes-and-mappings">
<span id="create-indexes-mappings-7-x"></span><h2><a class="toc-backref" href="#id4" role="doc-backlink">3. Creating Indexes and Mappings</a><a class="headerlink" href="#creating-indexes-and-mappings" title="Link to this heading"></a></h2>
<p>Indexes are used by Elasticsearch to store the information sent by Logstash. Mappings are a way to structure that data using a JSON format.
Let’s see an example to structue the log parsed above, for more information about mappings read <a class="reference external" href="https://www.elastic.co/guide/en/elasticsearch/reference/7.1/mapping.html">here</a>:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>PUT<span class="w"> </span>/secure
<span class="o">{</span>
<span class="w">  </span><span class="s2">&quot;mappings&quot;</span>:<span class="o">{</span>
<span class="w">    </span><span class="s2">&quot;properties&quot;</span>:<span class="o">{</span>
<span class="w">      </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="o">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span><span class="w"> </span>:<span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="w"> </span><span class="o">}</span>,
<span class="w">      </span><span class="s2">&quot;system_hostname&quot;</span>:<span class="o">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="w"> </span><span class="o">}</span>,
<span class="w">      </span><span class="s2">&quot;sshd_guest_ip&quot;</span>:<span class="o">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;ip&quot;</span><span class="w"> </span><span class="o">}</span>,
<span class="w">      </span><span class="s2">&quot;sshd_guest_port&quot;</span>:<span class="o">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;integer&quot;</span><span class="w"> </span><span class="o">}</span>,
<span class="w">      </span><span class="s2">&quot;sshd_guest_signature&quot;</span>:<span class="o">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="w"> </span><span class="o">}</span>,
<span class="w">      </span><span class="s2">&quot;sshd_event&quot;</span>:<span class="o">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="w"> </span><span class="o">}</span>,
<span class="w">      </span><span class="s2">&quot;sshd_method&quot;</span>:<span class="o">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="w"> </span><span class="o">}</span>,
<span class="w">      </span><span class="s2">&quot;sshd_user&quot;</span>:<span class="o">{</span><span class="w"> </span><span class="s2">&quot;type&quot;</span>:<span class="w"> </span><span class="s2">&quot;keyword&quot;</span><span class="w"> </span><span class="o">}</span>
<span class="w">    </span><span class="o">}</span>
<span class="w">  </span><span class="o">}</span>
<span class="o">}</span>
</pre></div>
</div>
<p>Elasticsearch offers a REST API to manage the data. So, <em>PUT</em> inserts new information into Elasticsearch. Therefore, if there exists an index with the name <em>secure</em>, Elasticsearch will throw an error.
In that case use <em>POST</em>, which is used to update the existing information. So, what does all that stuff mean?:</p>
<ul class="simple">
<li><p><code class="code highlight json docutils literal highlight-json"><span class="s2">&quot;mappings&quot;</span></code> refers to the property that describes the structure of the index.</p></li>
<li><p><code class="code highlight json docutils literal highlight-json"><span class="s2">&quot;properties&quot;</span></code> as its name says, is used to describe the properties of the mappings.</p></li>
<li><p>The rest of the items are the fields and its types. These fields describe the types of the information parsed in Logstash. For example:</p>
<ul>
<li><p><code class="code highlight json docutils literal highlight-json"><span class="s2">&quot;sshd_guest_ip&quot;</span></code> is the field that represents the ip address parsed from the logs. Its type is <code class="code highlight json docutils literal highlight-json"><span class="s2">&quot;ip&quot;</span></code>. Elasticsearch has a built-in type called <code class="code highlight json docutils literal highlight-json"><span class="s2">&quot;ip&quot;</span></code> which eases the indexation and visualization of ip addresses.</p></li>
<li><p>The <code class="code highlight json docutils literal highlight-json"><span class="s2">&quot;type&quot;</span></code> field is useful to differentiate the logs sent from a single source, in this case <code class="code highlight bash docutils literal highlight-bash">/var/log/secure</code>. Recall the <code class="code highlight ruby docutils literal highlight-ruby"><span class="n">add_field</span></code> option under the Grok plugin in <a class="reference internal" href="#how-to-filter-7-x"><span class="std std-ref">2. Filtering</span></a>, it was added the field: “type” =&gt; “sshd_login_attempt”. Therefore, in case of indexing the sudo commands logs, change this field to something like: “type” =&gt; “secure_sudo_command”. This is how to differentiate them easily.</p></li>
</ul>
</li>
</ul>
</div></blockquote>
</section>
<section id="adding-the-log-path-to-filebeat">
<span id="add-path-filebeat-7-x"></span><h2><a class="toc-backref" href="#id5" role="doc-backlink">4. Adding the log path to Filebeat</a><a class="headerlink" href="#adding-the-log-path-to-filebeat" title="Link to this heading"></a></h2>
<p>Now that the data is filtered and properly structured, it’s time to start sending it to Logstash. Go to the machine that has the Filebeat service, edit the file <code class="code highlight bash docutils literal highlight-bash">/etc/filebeat/filebeat.yml</code>.
Under the section <code class="code highlight yaml docutils literal highlight-yaml"><span class="nt">filebeat.inputs</span><span class="p">:</span></code> add:</p>
<blockquote>
<div><div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="linenos">1</span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">log</span>
<span class="linenos">2</span><span class="w">  </span><span class="nt">paths</span><span class="p">:</span>
<span class="linenos">3</span><span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/var/log/secure*</span>
<span class="linenos">4</span><span class="w">  </span><span class="nt">fields</span><span class="p">:</span>
<span class="linenos">5</span><span class="w">    </span><span class="nt">fromsecure</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="linenos">6</span><span class="w">  </span><span class="nt">fields_under_root</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
</pre></div>
</div>
<p>What does it mean?:</p>
<ul class="simple">
<li><p>The first line indicates the type of information that will be collected.</p></li>
<li><p>The second line indicates the paths where the new logging source is located, in this case <code class="code highlight yaml docutils literal highlight-yaml"><span class="l l-Scalar l-Scalar-Plain">/var/log/</span></code>, and <code class="code highlight yaml docutils literal highlight-yaml"><span class="l l-Scalar l-Scalar-Plain">secure*</span></code> matches all the logs that start with the name <em>secure</em>. This wildcard is used becase some logs have a date at the end of its name, so it will be painful to add over and over again a path when a log appears in <code class="code highlight yaml docutils literal highlight-yaml"><span class="l l-Scalar l-Scalar-Plain">/var/log/</span></code>.</p></li>
<li><p>The fourth line, <code class="code highlight yaml docutils literal highlight-yaml"><span class="l l-Scalar l-Scalar-Plain">fields</span></code>, indicates to Filebeat to add a new field in to the JSON sent to Logstash. Recall the first <code class="code highlight ruby docutils literal highlight-ruby"><span class="k">if</span></code> sentence in the <a class="reference internal" href="#how-to-filter-7-x"><span class="std std-ref">2. Filtering</span></a> section. Well, this field is added so that all the different logging sources can be differentiated in Logstash.</p></li>
<li><p>The last option, <code class="code highlight yaml docutils literal highlight-yaml"><span class="l l-Scalar l-Scalar-Plain">fields_under_root</span></code>, is used to add the fields under the root of the JSON, and not nested into a field called <code class="code highlight yaml docutils literal highlight-yaml"><span class="l l-Scalar l-Scalar-Plain">beat</span></code>, which is the default behavior.</p></li>
</ul>
<p>Restart the Filebeat service and hopefully everything will work perfectly.
Otherwise, recall to check the logs usually under <code class="code highlight bash docutils literal highlight-bash">/usr/share/&lt;service&gt;/logs</code> or under <code class="code highlight bash docutils literal highlight-bash">/var/log/&lt;service&gt;</code>.</p>
</div></blockquote>
</section>
<section id="create-index-patterns">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">5. Create Index Patterns</a><a class="headerlink" href="#create-index-patterns" title="Link to this heading"></a></h2>
<p>With some data indexed in Elasticsearch, create <strong>Index Patterns</strong>. These are used by Kibana to match (using regular expressions) indexes and take the data that will be plotted from those indexes matched by some pattern.</p>
<p>Go to <strong>Management</strong> -&gt; <strong>Index Pattern</strong> -&gt; <strong>Create index pattern</strong>. Select its name/pattern, and as time filter field select <code class="code highlight json docutils literal highlight-json"><span class="s2">&quot;@timestamp&quot;</span></code>.</p>
</section>
<section id="plot-the-data">
<h2><a class="toc-backref" href="#id7" role="doc-backlink">6 . Plot the data</a><a class="headerlink" href="#plot-the-data" title="Link to this heading"></a></h2>
<p>One of the easiest plots that can be created is a frequency histogram. Nevertheless, there are lots of more features that Kibana <a class="reference external" href="https://www.elastic.co/guide/en/kibana/current/visualize.html">offers</a>.</p>
<p>In Kibana go to <strong>Visualize</strong>, press the <strong>+</strong> button, select the type of visualization, in this case, <strong>Vertical Bar</strong>. Afther this, select the index pattern that corresponds to the <strong>secure</strong> logs.
Then, to create a frequency historgram of the users that failed logging in follow these steps:</p>
<ol class="arabic simple">
<li><p>In the left hand side of the Kibana web page, there is a subsection called <strong>Buckets</strong>. Click on <strong>X-Axis</strong>.</p></li>
<li><p>As aggregation select <strong>Terms</strong>. For more information about Term <a class="reference external" href="https://www.elastic.co/guide/en/elasticsearch/reference/7.2/search-aggregations-bucket-terms-aggregation.html">aggregation</a>.</p></li>
<li><p>As field select <strong>sshd_user</strong>.</p></li>
<li><p>As custom label write: User name.</p></li>
<li><p>Now instead of <strong>X-Axis</strong> select <strong>Add sub-buckes</strong>. Then select <strong>Split Series</strong>.</p></li>
<li><p>Here as aggregation select <strong>Terms</strong> again.</p></li>
<li><p>As field select <strong>sshd_event</strong>.</p></li>
<li><p>Now type the following in the bar that is in the upper part of the Kibana’s GUI, the <strong>Filters</strong> bar: <code class="code highlight bash docutils literal highlight-bash">sshd_event<span class="w"> </span>:<span class="w"> </span><span class="s2">&quot;Failed&quot;</span></code>. This is called <strong>Kibana Query Language</strong>, it can be used to filter the data and plot only what is be useful. More information on this query language here, <a class="reference external" href="https://www.elastic.co/guide/en/kibana/7.2/kuery-query.html">Kibana Query Language</a>.</p></li>
<li><p>Click on the <strong>play</strong> button in the left hand side of the Kibana’s GUI.</p></li>
<li><p>Save the visualization with a descriptive name, something like: <em>[sshd] Failed attempts to log in</em>.</p></li>
<li><p>In case of not having a <strong>Dashboard</strong>, create a new one, then add the visualization. Up to this point it should look something like:</p></li>
</ol>
<img alt="Kibana vertical bars visualization." src="../../../../_images/visualization.png" />
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="testing.html" class="btn btn-neutral float-left" title="Testing" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../grafana/index.html" class="btn btn-neutral float-right" title="Grafana" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Creative Commons Attribution-NonCommercial 4.0 International License.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>